# Thoth

&nbsp;&nbsp;&nbsp;&nbsp; Named after the Egyptian god of the moon, of reckoning, of learning, and of writing, is a **_tokenizer_**, purposed for interpreting text input for large-scale language models, such as OpenAI's GPT series of models (e.g., GPT-3.5, GPT-4, GitHub Copilot), Google's PaLM and Gemini, Meta's LLaMA family, and Anthropic's Claude models.

### Inspiration

&nbsp;&nbsp;&nbsp;&nbsp; I just felt like it. It seems like the bottleneck of LLMs at the moment, so it would be good to research and develop one, understand up-to-date architectures, and produce better open source implementations in hopes to provide AI at NLP.

### How to Use

&nbsp;&nbsp;&nbsp;&nbsp; TBD

### Architecture

&nbsp;&nbsp;&nbsp;&nbsp; TBD

### Topics

&nbsp;&nbsp;&nbsp;&nbsp; TBD

<!-- Template:
- **Languages**: Python, SQL
- **Libraries/Frameworks/Tools**: Pandas, Juypter Notebooks
- <ins>**Other**</ins>:
  - **Concepts**: ER Diagrams, Relational Schema Mapping, Normal Forms, Data Redundancy, Indexes, Database Performance, Multi-classification, Random-Forest Classification, Feature Engineering & Selection -->
